\section{Conclusions}
We have introduced offer and resource revocation in order to improve fairness when using Apache Mesos
to manage clusters. Deploying offer revocation to timeout excessively indecisive frameworks permits the
system to recover otherwise wasted resources and provide more offers to more frameworks. We implemented
resource revocation to allow frameworks to obtain more reliable guarantees of system resources. This
extension allows frameworks to put hard limits on task latencies and thus be able to fulfill SLAs. We
found that since offer based DRF in Mesos already did a reasonable job in providing fairness of
resources, it was sufficient to focus revocation on fulfilling needs and not desires of frameworks. This
ultimately minimized goodput loss due to revocation.

We evaluated our revocation mechanisms on a small cluster using synthetic frameworks designed to model
problem scenarios that arise in a production cluster. Our results show that our revocation strategy
works well to ensure fairness by minimizing task latencies at the cost of minimal goodput loss. Resource
revocation was also able to maintain better resource stability and consistencies to participating
frameworks. Greedy frameworks were prevented from locking out undersubscribed frameworks.
Undersubscribed frameworks are able to get a resonable slice of the system without fear of being edged
out the system by greedy frameworks.

\section{Future Work}
In this paper we chose the simplest resource revocation scheme. To continue this project, we would
examine different revocation policies. One possible idea would be to reduce the frequency of revocations
(since currently we check for revokation at every Mesos heartbeat). Reducing the frequency would
obviously increase task latency but could also possibly reduce goodput loss by preventing Mesos from
overreacting to transient utilization spikes. Other possible extensions explore broad adjustments to the
revocation algorithm. Currently, the revocation routine iterates through oversubscribed rameworks in an
arbitrary order until all resource needs are satisfied. A possible alternative would be to only revoke a
handful of tasks every cycle and focus specifically on the most oversubscribed framework. This would
possibly spread out the goodput impact amongst multiple oversubscribed frameworks providing a fairer
punishment for oversubscription at the expense of taking more time to fulfill all needs.

Adding a voluntary revocation stage before forcing Mesos to directly revoke tasks would also be
beneficial. Here, the master allocator would first send a warning message to oversubscribed frameworks
giving them a chance to voluntarily terminate excess tasks (allowing those frameworks to pick a better
termination order than youngest first) before Mesos initiated revocation. Since not all frameworks are
like to respond (for example, legacy frameworks not updated to the new Mesos communication model), there
is some design space in deciding how many extra resources Mesos should ask frameworks to voluntarily
surrender.

\section{Acknowledgements}
Special thanks to Benjamin Hindman and the other Mesos developers at UC Berkeley for providing support in
understanding the Mesos codebase and discussing possible implementation details for resource revocation.
Thank you to Professors Anthony Joseph and John Kubiatowicz for providing feedback on the project
progress and contributing general implementation ideas.
