\section{Introduction}
\label{sec:intro}

As the data analytics and processing needs of companies grow, systems designers are looking more and more to using clusters in order to provide for those needs. Clustering of compute resources permits more efficient allocation of compute resources to tasks relative to na\"{\i}ve static partitioning by allowing unused resources to quickly and easily be shared for use by other tasks. This lets companies to more effectively deal with dynamic workloads by giving compute clients the ability to pickup or shed resources in time as their computational requirements shift. For example, during the day a retailer has to devote substantive processing power to ensure all transactions are completed in a timely manner such that the retailer can do real business. However, during the evening when transaction loads are light, the excess resources are better spent doing data analysis on the transaction data to track buying trends and better inform managers for making business decisions. These clusters need specific cluster management software that maps compute nodes to clients and provides administrators a convenient point to monitor the status and utilization of all agents in the system.
Apache Mesos is one such cluster manager that was originally developed by the UC Berkeley AMP Lab and is currently in use to manage clusters at Twitter and Conviva [1,2 REF]. The Mesos API model does not require frameworks to specify the fine details of what resources the participating frameworks (the clients) need. Rather, Mesos compiles a listing of available resources at nodes into an offer that it then presents to a framework. The framework may then analyze the resources in the offer and then cherry-pick the specific nodes onto which Mesos should launch new tasks for the framework. This allows frameworks to fulfill arbitrarily complex resource allocation requirements without complicating the Mesos scheduler. For example, by tracking its previous allocations, frameworks could ensure its tasks are all located on the same rack in the system (for better IPC speed) or far away from each other (for better resiliency to failure), only launched on nodes with internet access (for webservers), or, for Hadoop-like tasks, preferentially launched on nodes already containing the data to be processed (to minimize data fetch time). To enforce fairness amongst all frameworks, the allocator in Mesos implements dominant resource fairness [3 REF] and only makes new offers to frameworks in order of increasing dominant share. Over time, this is expected to balance out the system amongst all frameworks. Mesos has been found to be highly scalable (up to 50000 nodes) and competitive when run against static partitioning for various Hadoop and Spark workloads.
Producing fairness by ordering offers to frameworks, unfortunately, does not work in the general case. The original evaluation of Mesos focused on MapReduce or MapReduce-like jobs, which are generally characterized by having a small footprint and, critically, low execution times. Thus, for any small interval of time during those tests, tasks were ending thus freeing up resources on nodes allowing offers to be made to undersubscribed frameworks. However, this behavior is not guaranteed in general, particularly in systems containing frameworks with `long' running tasks. Assuming these same frameworks are capable of spawning speculative execution (in order to avoid letting cluster resources go to waste during times of low interest), all system resources will be reserved for extended periods of time leaving new frameworks (or equivalently, other frameworks that suddenly need a bunch of resources to respond to a workload burst) unable to get resources in a timely manner. These high latencies may be unacceptable for interactive frameworks that must launch tasks immediately to respond to user queries. The implementation details ...
